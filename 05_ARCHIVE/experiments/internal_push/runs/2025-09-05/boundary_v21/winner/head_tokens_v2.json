{
  "head_tokens": [
    "W",
    "ECA",
    "NSE",
    "ETH",
    "ETEX",
    "TI",
    "SCOD",
    "EEAS",
    "TNORTHEAS",
    "TW",
    "ESE",
    "TTH",
    "ECOURS",
    "ETRU",
    "EREA",
    "DTHE",
    "NSE",
    "EBERLI",
    "NCLOC",
    "KTHEJO"
  ],
  "head_fword_count": 0,
  "head_fwords": [],
  "tokenization": "v2",
  "notes": "Current decision tokenization (canonical cuts, no inferred splits)"
}